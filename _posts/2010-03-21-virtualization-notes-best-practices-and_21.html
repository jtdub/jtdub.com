---
layout: post
title: Virtualization Notes, Best Practices, and Gotcha's
date: '2010-03-21T16:08:00.001-05:00'
author: jtdub
tags:
- Virtualization
- Hyper-V
- VMware
modified_time: '2019-04-11T11:09:40.385-05:00'
blogger_id: tag:blogger.com,1999:blog-2200496390325245811.post-684912905063645929
blogger_orig_url: https://www.packetgeek.net/2010/03/virtualization-notes-best-practices-and_21.html
---

I spent last week attending the Virtualization Pro Summit. I came away with a wealth of information that I'm still compiling, wrapping my head around, and figuring out where and how I can implement what. Below are some of the notes that I took away from the conference.
<br/>
<br/>
<b>
 General Virtualization
</b>
<br/>
<ul>
 <li>
  Memory is the first bottle neck in virtualization.
 </li>
 <ul>
  <li>
   When sizing a server, be sure to use servers that can handle at least 128GB of RAM. It doesn't mean that you will need to purchase a server with 128GB of RAM off the bat. It will allow for proper expansion.
  </li>
  <li>
   If possible, use DDR3 RAM and buy in sticks of three.
  </li>
  <li>
   Balance the memory allocations across the CPU channels.
  </li>
  <li>
   Leave a buffer to the amount of logical RAM allocated to the amount of physical RAM in the server.
  </li>
 </ul>
 <li>
  The speed of your hard disk subsystem is probably the second bottleneck that will be encountered.
 </li>
 <ul>
  <li>
   For iSCSI SANs, use multiple load balanced connections to the SAN to get the desired bandwidth.
  </li>
  <li>
   For the best performance, purchase a SAN or DAS that uses newer SAS (serially attached SCSI) hard drives.
  </li>
  <li>
   Fiber Channel over Ethernet (FCoE) will provide the better performance as it doesn't have the overhead of the IP protocol, but for the time being, iSCSI will provide the most bang for the buck.
  </li>
  <li>
   SAS hard drives provide 384MBps throughput.
  </li>
  <li>
   15K SAS drives will provide the best performance.
  </li>
  <li>
   You can allocate additional RAM for x64 guests for disk caching to compensate for an overloaded hard disk subsystem. This will greatly enhance performance for servers that are hard on disk I/O, such as Exchange, SQL, and Virtual Desktops (VDI).
  </li>
 </ul>
 <li>
  Processor Management:
 </li>
 <ul>
  <li>
   Target CPU usage is around 60 - 70%, combined for all guest VMs and the VM host.
  </li>
  <li>
   A four to one ratio of CPU core to guest VM vCPU is a good ratio to start off with after taking other factors into account (RAM, disk I/O, networking, etc). After that you can add or remove VMs as needed.
  </li>
  <li>
   Multi-socket x64 processors provide the best performance.
  </li>
  <li>
   For SMP Applications - vCPU's shouldn't out number the physical CPU's.
  </li>
 </ul>
 <li>
  Dynamic VM moves (VMWare vMotion / Microsoft Live Migration)
 </li>
 <ul>
  <li>
   You will need to plan your VM clusters so that not any single VM host is over loaded. If a VM host goes down in a cluster, it will cause a domino effect.
  </li>
 </ul>
 <li>
  Network Management:
 </li>
 <ul>
  <li>
   NIC teaming or 10GB Ethernet will provide the best performance for heavy usage.
  </li>
  <li>
   Isolate the console network and protect the VM hosts at all costs.
  </li>
  <li>
   Isolate the cluster heartbeat (vMotion / Live Migration) traffic on a physical separate switch.
  </li>
  <li>
   The console network and cluster heartbeat network can be on the same network if need be.
  </li>
 </ul>
 <li>
  BIOS:
 </li>
 <ul>
  <li>
   Enable:
  </li>
  <ul>
   <li>
    Hyper-threading
   </li>
   <li>
    Hardware assisted virtualization
   </li>
   <li>
    Data Execution Prevention
   </li>
  </ul>
  <li>
   Disable:
  </li>
  <ul>
   <li>
    All power save settings
   </li>
  </ul>
 </ul>
 <li>
  Host / Guest Capacity Planning:
 </li>
 <ul>
  <li>
   http://www.vkernal.com
  </li>
  <li>
   http://www.teamquest.com/solutions-products/products/model/
  </li>
 </ul>
 <li>
  Disk Raid:
 </li>
 <ul>
  <li>
   Raid 5 is a good compromise of performance and fault tollerance.
  </li>
  <li>
   Raid 10 provides the best performance, but is costs more on disk usage.
  </li>
  <li>
   Raid 1 can be used for VM hosts.
  </li>
 </ul>
</ul>
<ul>
</ul>
<b>
 VMWare vSphere 4.0
</b>
<br/>
<ul>
 <li>
  Memory Management:
 </li>
 <ul>
  <li>
   ESX(i) will consolidate identical memory pools. Therefore it's better to  try to run the same types of operating systems and applications on a VM  host.
  </li>
  <li>
   Balloon driver is a function that allows a VM host to dynamically allocate RAM to a guest. If this feature is used, careful planning will be needed as to not over-allocate RAM.
  </li>
 </ul>
 <li>
  Disk Provisioning:
 </li>
 <ul>
  <li>
   Thin provisioning is an option, but may thick provisioning will provide better performance.
  </li>
  <li>
   If thin provisioning is used, careful planning will be needed as it allows you to potentially over-allocate available disk space.
  </li>
 </ul>
 <li>
  Snapshots:
 </li>
 <ul>
  <li>
   Don't leave snapshots active because you might need them.
  </li>
  <li>
   Try to keep snapshot sizes and the number of them to a minimum.
  </li>
  <li>
   Active snapshots may reduce performance on the VM.
  </li>
  <li>
   Deleting snapshots (especially large ones) and playing them back into a base image reduces performance. Depending on the size, it can take a LONG time.
  </li>
 </ul>
 <li>
  General performance:
 </li>
 <ul>
  <li>
   Minimize the number of vSwitches
  </li>
  <li>
   Don't use the ESX(i) console to manage guests.
  </li>
  <li>
   Consider using an iSCSI HBA on older hosts. On newer hosts it may be a detriment to performance. vSphere doesn't support TOE NIC cards.
  </li>
  <li>
   Install VMware-Tools.
  </li>
 </ul>
</ul>